{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Odera2023/RAG/blob/main/odera_rag_practical1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f164475-a1e6-438d-94fa-44e973cc0831",
      "metadata": {
        "id": "7f164475-a1e6-438d-94fa-44e973cc0831"
      },
      "source": [
        "### 1. Install & Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2d4bb2b3-9750-42cc-90d8-6830ac772cfa",
      "metadata": {
        "scrolled": true,
        "id": "2d4bb2b3-9750-42cc-90d8-6830ac772cfa",
        "outputId": "d32a56a3-7753-4708-9d63-083ff5fec699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.3.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting langchain_nvidia_ai_endpoints\n",
            "  Downloading langchain_nvidia_ai_endpoints-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.55)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from langchain_nvidia_ai_endpoints) (3.13.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_nvidia_ai_endpoints)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.22.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.12)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading chromadb-1.3.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_nvidia_ai_endpoints-1.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.39.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m841.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=53226a6b99eb25803de9d6dd9c39f9b0919971b54e419a4f7d5274f3f77e3343\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, filetype, durationpy, uvloop, urllib3, pyproject_hooks, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain_nvidia_ai_endpoints, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.6 coloredlogs-15.0.1 durationpy-0.10 filetype-1.2.0 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-text-splitters-1.0.0 langchain_nvidia_ai_endpoints-1.0.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.39.0 opentelemetry-exporter-otlp-proto-common-1.39.0 opentelemetry-exporter-otlp-proto-grpc-1.39.0 opentelemetry-proto-1.39.0 opentelemetry-sdk-1.39.0 opentelemetry-semantic-conventions-0.60b0 posthog-5.4.0 pybase64-1.4.3 pypika-0.48.9 pyproject_hooks-1.2.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-core langchain-text-splitters chromadb langchain_nvidia_ai_endpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "634d46a1-b4aa-4f07-a2a8-c1161a34d238",
      "metadata": {
        "id": "634d46a1-b4aa-4f07-a2a8-c1161a34d238",
        "outputId": "821eaeda-64e7-447b-f946-f72a31ea8b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.text_splitter'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1886437797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_nvidia_ai_endpoints\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatNVIDIA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNVIDIAEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunnableParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnablePassthrough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.text_splitter'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Imports\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
        "import chromadb\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad25c775-3540-4eb3-b8c1-4e6eb54363be",
      "metadata": {
        "id": "ad25c775-3540-4eb3-b8c1-4e6eb54363be"
      },
      "source": [
        "### 2. Initialize Embeddings + LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb6476b-9177-4b89-85b9-b6c98a77271f",
      "metadata": {
        "id": "fdb6476b-9177-4b89-85b9-b6c98a77271f"
      },
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
        "\n",
        "# Instruction LLM (chat model)\n",
        "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c812594-22a7-44b6-b2e1-cefc1a4ed794",
      "metadata": {
        "id": "1c812594-22a7-44b6-b2e1-cefc1a4ed794"
      },
      "source": [
        "### 3. Load a Document (Simple Text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ae46bfd-cec3-45b7-859c-2d80aaf573ea",
      "metadata": {
        "scrolled": true,
        "id": "4ae46bfd-cec3-45b7-859c-2d80aaf573ea",
        "outputId": "040b4734-258a-4310-a52e-07eb7b79ab32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/site-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/site-packages (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/site-packages (0.3.11)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/site-packages (1.3.5)\n",
            "Requirement already satisfied: langchain_nvidia_ai_endpoints in /usr/local/lib/python3.11/site-packages (0.3.19)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/site-packages (from langchain) (0.4.49)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/site-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/site-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/site-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.39.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.39.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.39.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/site-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (14.2.0)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/site-packages (from langchain_nvidia_ai_endpoints) (3.13.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/site-packages (from langchain_nvidia_ai_endpoints) (1.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.22.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.41.1)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.0 in /usr/local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.0 in /usr/local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b0 in /usr/local/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Downloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-6.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-core langchain-text-splitters chromadb langchain_nvidia_ai_endpoints pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "928f0227-7f72-4db2-af58-cf3f70f3064e",
      "metadata": {
        "scrolled": true,
        "id": "928f0227-7f72-4db2-af58-cf3f70f3064e",
        "outputId": "02aa7e3e-3aad-4d20-d87d-d3dceb12729e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-11-10T11:43:58+00:00', 'author': '', 'keywords': '', 'moddate': '2024-11-10T11:43:58+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'LangChain.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}, page_content='LangChain\\nVasilios Mavroudis\\nAlan Turing Institute\\nvmavroudis@turing.ac.uk\\nAbstract. LangChain is a rapidly emerging framework that offers a ver-\\nsatile and modular approach to developing applications powered by large\\nlanguage models (LLMs). By leveraging LangChain, developers can sim-\\nplify complex stages of the application lifecycle—such as development,\\nproductionization, and deployment—making it easier to build scalable,\\nstateful, and contextually aware applications. It provides tools for han-\\ndling chat models, integrating retrieval-augmented generation (RAG),\\nand offering secure API interactions. With LangChain, rapid deployment\\nof sophisticated LLM solutions across diverse domains becomes feasible.\\nHowever, despite its strengths, LangChain’s emphasis on modularity and\\nintegration introduces complexities and potential security concerns that\\nwarrant critical examination. This paper provides an in-depth analysis\\nof LangChain’s architecture and core components, including LangGraph,\\nLangServe,andLangSmith.Weexplorehowtheframeworkfacilitatesthe\\ndevelopment of LLM applications, discuss its applications across multi-\\nple domains, and critically evaluate its limitations in terms of usability,\\nsecurity, and scalability. By offering valuable insights into both the capa-\\nbilities and challenges of LangChain, this paper serves as a key resource\\nfor developers and researchers interested in leveraging LangChain for\\ninnovative and secure LLM-powered applications.\\nKeywords: LangChain · Large Language Models· LLM Applications·\\nModular Framework\\nThe emergence of large language models (LLMs) such as OpenAI’s o1 [13],\\nGPT-4o [12], Google’s Gemini [14], and Meta’s LLaMA [16] has revolutionized\\nthe field of natural language processing (NLP). These advanced models have un-\\nlocked unprecedented capabilities in understanding and generating human-like\\ntext, enabling applications that range from intelligent conversational agents to\\nsophisticated data analysis tools. However, harnessing the full potential of LLMs\\nin real-world applications presents significant challenges. Developers must nav-\\nigate complexities related to model integration, state management, scalability,\\ncontextual awareness, and security.\\nLangChain has rapidly gained prominence as a powerful framework designed\\nto address these challenges in developing LLM-powered applications [2]. By\\nproviding a modular and flexible architecture, LangChain simplifies the com-\\nplexities inherent in working with LLMs, enabling developers to build scalable,')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load a PDF file\n",
        "loader = PyPDFLoader(\"LangChain.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "documents[:1]   # Preview the first page/document chunk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1bca5e-04d7-4a12-b656-a3e81846c94c",
      "metadata": {
        "id": "4b1bca5e-04d7-4a12-b656-a3e81846c94c"
      },
      "source": [
        "### 4. Chunk the Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9c9b23-6599-4b4e-86d4-cafda914da36",
      "metadata": {
        "id": "3a9c9b23-6599-4b4e-86d4-cafda914da36",
        "outputId": "9e481a0a-5a52-4ef3-b0f1-0f72d80241ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb75d1c1-96b4-4e88-af11-99e4e3e1f37e",
      "metadata": {
        "id": "cb75d1c1-96b4-4e88-af11-99e4e3e1f37e"
      },
      "source": [
        "### 5. Create & Persist Chroma Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9791a2-04d7-4770-85e2-64bb06a4ed5a",
      "metadata": {
        "id": "cc9791a2-04d7-4770-85e2-64bb06a4ed5a"
      },
      "outputs": [],
      "source": [
        "chroma_client = chromadb.Client()\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embedder,\n",
        "    client=chroma_client,\n",
        "    collection_name=\"rag_tutorial\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a03da4-56e2-42ea-98f0-1b3eaa00c71b",
      "metadata": {
        "id": "98a03da4-56e2-42ea-98f0-1b3eaa00c71b"
      },
      "source": [
        "### 6. Create Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c93fe1a-ab2c-418a-9905-430efe6c911c",
      "metadata": {
        "id": "4c93fe1a-ab2c-418a-9905-430efe6c911c"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d332925a-5b1b-4a35-b099-0f0c67a510de",
      "metadata": {
        "id": "d332925a-5b1b-4a35-b099-0f0c67a510de"
      },
      "source": [
        "### 7. Build the RAG Runnable Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a481aa-4210-43bb-bf38-020c72e3e73b",
      "metadata": {
        "id": "60a481aa-4210-43bb-bf38-020c72e3e73b"
      },
      "outputs": [],
      "source": [
        "# Prompts and output parsers\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Runnable\n",
        "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7063956e-aeb6-456d-b013-a0d5927fefea",
      "metadata": {
        "id": "7063956e-aeb6-456d-b013-a0d5927fefea"
      },
      "outputs": [],
      "source": [
        "# Define chat prompt template\n",
        "context_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Answer the question using only the context\"\n",
        "    \"\\n\\nRetrieved Context: {context}\"\n",
        "    \"\\n\\nUser Question: {question}\"\n",
        "    \"\\nAnswer the user conversationally. User is not aware of context.\"\n",
        ")\n",
        "\n",
        "# Build a RAG chain using LCEL (LangChain Expression Language)\n",
        "# LCEL allows chaining runnables and parsing outputs\n",
        "rag_chain = RunnableParallel({\n",
        "    \"context\": retriever | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])),\n",
        "    \"question\": RunnablePassthrough()\n",
        "}) | (\n",
        "    lambda inputs: context_prompt.format(context=inputs[\"context\"], question=inputs[\"question\"])\n",
        ") | instruct_llm | StrOutputParser()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9250e446-cad3-40e3-810d-aeaacf0306aa",
      "metadata": {
        "scrolled": true,
        "id": "9250e446-cad3-40e3-810d-aeaacf0306aa",
        "outputId": "f3e13734-ef7e-4417-c92e-ab6906863d6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            " LangChain RAG, or Retrieval-Augmented Generation, is a feature that enables language models to use up-to-date external knowledge bases to enhance the accuracy of their responses. LangChain's implementation of RAG uses document loaders and text splitters to preprocess documents for efficient retrieval, embedding models and vector stores to embed documents into vector spaces for similarity-based retrieval, and supports structured outputs like JSON for easy integration with other applications. Furthermore, it maintains conversation memory for continuity, especially useful for applications requiring persistent context such as customer support.\n"
          ]
        }
      ],
      "source": [
        "# Manual invoke to test the RAG chain\n",
        "response = rag_chain.invoke(\"What does the document say about LangChain RAG?\")\n",
        "print(\"Response:\\n\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229d7e9d-e70e-4c5f-98a8-69c939488a0f",
      "metadata": {
        "id": "229d7e9d-e70e-4c5f-98a8-69c939488a0f",
        "outputId": "e83c6739-239e-4d65-85fb-2e4864379e46"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter your question about the document:  What is Langserve from the document\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant Response:\n",
            " LangServe is a component of the LangChain ecosystem that focuses on deploying large language model (LLM) applications as scalable REST APIs. It allows developers to create production-grade APIs that can be interacted with by external systems and users. One of the main strengths of LangServe is its ability to handle multiple API requests simultaneously, providing consistent performance even under high traffic volumes. This makes it ideal for production environments where maintaining low response times is crucial. Furthermore, LangServe integrates with LangSmith for observability features like tracing, logging, and performance monitoring, enabling developers to track API performance and optimize applications based on real-time data.\n"
          ]
        }
      ],
      "source": [
        "# Ask user for a question using standard Python input\n",
        "user_question = input(\"Enter your question about the document: \")\n",
        "\n",
        "# Run the RAG chain with user input\n",
        "user_response = rag_chain.invoke(user_question)\n",
        "print(\"Assistant Response:\\n\", user_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6287cb5-7872-4412-9f5d-c25a1f20e57b",
      "metadata": {
        "id": "f6287cb5-7872-4412-9f5d-c25a1f20e57b"
      },
      "source": [
        "### Conversation State (Chat Memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa193709-c18c-4bb9-b061-cacfad311eba",
      "metadata": {
        "id": "fa193709-c18c-4bb9-b061-cacfad311eba"
      },
      "outputs": [],
      "source": [
        "# Simple conversation history\n",
        "chat_history = []\n",
        "\n",
        "def conversational_rag(user_query):\n",
        "    \"\"\"Runs RAG with conversation history (very simple state).\"\"\"\n",
        "    global chat_history\n",
        "\n",
        "    # Join past messages into a readable history string\n",
        "    history_text = \"\\n\".join([\n",
        "        f\"{h['role']}: {h['content']}\" for h in chat_history\n",
        "    ])\n",
        "\n",
        "    # Append conversation history to user query\n",
        "    final_query = f\"\"\"\n",
        "Conversation so far:\n",
        "{history_text}\n",
        "\n",
        "User: {user_query}\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Run RAG chain\n",
        "    response = rag_chain.invoke(final_query)\n",
        "\n",
        "    # Save turn to history\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_query})\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd5c546-b2a2-4e66-8cd7-0c617d9e4515",
      "metadata": {
        "id": "cbd5c546-b2a2-4e66-8cd7-0c617d9e4515"
      },
      "source": [
        "#### Using Langchain Messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f838d4df-c384-44df-86c2-c69e6505dfb9",
      "metadata": {
        "id": "f838d4df-c384-44df-86c2-c69e6505dfb9"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d165f7b-1e5c-41ac-877c-5a9da310010d",
      "metadata": {
        "id": "9d165f7b-1e5c-41ac-877c-5a9da310010d"
      },
      "outputs": [],
      "source": [
        "chat_history = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f8f406-67aa-4916-93d8-7cd3dbbf4633",
      "metadata": {
        "id": "d6f8f406-67aa-4916-93d8-7cd3dbbf4633"
      },
      "outputs": [],
      "source": [
        "def conversational_rag(user_query):\n",
        "    \"\"\"RAG with proper message objects instead of raw dicts.\"\"\"\n",
        "\n",
        "    global chat_history\n",
        "\n",
        "    # Convert message objects to readable text for the RAG chain\n",
        "    history_text = \"\\n\".join([\n",
        "        f\"{type(msg).__name__}: {msg.content}\"\n",
        "        for msg in chat_history\n",
        "    ])\n",
        "\n",
        "    # Build final combined query\n",
        "    final_query = f\"\"\"\n",
        "Conversation so far:\n",
        "{history_text}\n",
        "\n",
        "User: {user_query}\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Run RAG chain\n",
        "    response = rag_chain.invoke(final_query)\n",
        "\n",
        "    # Update history using proper LangChain message classes\n",
        "    chat_history.append(HumanMessage(content=user_query))\n",
        "    chat_history.append(AIMessage(content=response))\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a55f2b-d958-4ab6-b886-6d4d853da009",
      "metadata": {
        "id": "83a55f2b-d958-4ab6-b886-6d4d853da009",
        "outputId": "2eeff594-37f0-4581-f446-ec61b80ae5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔵 RAG Chatbot is ready! Type 'exit' to quit.\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "You:  Hi there, what is the name of your model. I am Ebuka\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 Chatbot: Hello Ebuka! I'm an assistant built using a model from LangChain. It's a system designed for complex, multi-turn conversations like ours, helping me maintain context and provide contextually aware responses. It's a pleasure to meet you! \n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "You:  what is my name again?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 Chatbot: Hello there! Your name is Ebuka, remember? I'm here to assist you today. Let me know if you have any questions or need help with something! \n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "You:  what does the document say about LangServe, and reference my name in your response\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 Chatbot: LangServe is a component of LangChain that's designed for scalable API deployment. Essentially, it enables the integration of complex language models into various applications, Ebuka. This makes it easier for developers to create functional and contextually aware solutions. \n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "You:  quit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🟢 Chatbot: Goodbye! 👋\n"
          ]
        }
      ],
      "source": [
        "print(\"🔵 RAG Chatbot is ready! Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"🟢 Chatbot: Goodbye! 👋\")\n",
        "        break\n",
        "\n",
        "    bot_response = conversational_rag(user_input)\n",
        "\n",
        "    print(\"\\n🟢 Chatbot:\", bot_response, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad764d7e-a970-49ca-bc79-d6bb06d384a8",
      "metadata": {
        "id": "ad764d7e-a970-49ca-bc79-d6bb06d384a8"
      },
      "source": [
        "## LLM-as-Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc232fd-aec6-48b4-838f-289bc435ba78",
      "metadata": {
        "id": "7fc232fd-aec6-48b4-838f-289bc435ba78"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cef3841-314f-466b-b96d-5548c6d37220",
      "metadata": {
        "id": "6cef3841-314f-466b-b96d-5548c6d37220"
      },
      "source": [
        "### 1. Judge Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6b99ca-2647-4c61-8efb-bbd999caec1e",
      "metadata": {
        "id": "8b6b99ca-2647-4c61-8efb-bbd999caec1e"
      },
      "outputs": [],
      "source": [
        "judge_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "You are an evaluation assistant.\n",
        "\n",
        "You will judge whether the RAG answer is correct based ONLY on the provided context.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "User Question:\n",
        "{question}\n",
        "\n",
        "RAG Answer:\n",
        "{answer}\n",
        "\n",
        "Evaluate the correctness on a scale of 1 to 5.\n",
        "Explain your reasoning in 2–3 sentences.\n",
        "\n",
        "Return your answer in this format:\n",
        "Score: <number>\n",
        "Reason: <your explanation>\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b79c68b-ac7d-47da-bad7-f04e4a1d9904",
      "metadata": {
        "id": "7b79c68b-ac7d-47da-bad7-f04e4a1d9904"
      },
      "source": [
        "### 2. Create the Judge Chain (LCEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd50cf4-2bc8-43c9-8954-d076fb7cc64f",
      "metadata": {
        "id": "4bd50cf4-2bc8-43c9-8954-d076fb7cc64f"
      },
      "outputs": [],
      "source": [
        "judge_chain = judge_prompt | instruct_llm | StrOutputParser()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "772c444f-4afa-404f-a1b4-6dd4f683c881",
      "metadata": {
        "id": "772c444f-4afa-404f-a1b4-6dd4f683c881"
      },
      "source": [
        "### 3. Helper Function to Retrieve Context + Run Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c03eaf74-866a-42ac-af93-3638a1ada379",
      "metadata": {
        "id": "c03eaf74-866a-42ac-af93-3638a1ada379"
      },
      "outputs": [],
      "source": [
        "def evaluate_answer(question, rag_answer):\n",
        "    \"\"\"\n",
        "    Runs the LLM-as-a-Judge using the retrieved context and RAG answer.\n",
        "    \"\"\"\n",
        "    # Retrieve context for the question\n",
        "    retrieved_docs = retriever.invoke(question)\n",
        "    context_text = \"\\n\\n\".join([d.page_content for d in retrieved_docs])\n",
        "\n",
        "    # Run judge chain\n",
        "    judge_result = judge_chain.invoke({\n",
        "        \"context\": context_text,\n",
        "        \"question\": question,\n",
        "        \"answer\": rag_answer\n",
        "    })\n",
        "\n",
        "    return judge_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7da5cb-c001-4ab1-aaa8-d80885d97258",
      "metadata": {
        "id": "0a7da5cb-c001-4ab1-aaa8-d80885d97258"
      },
      "outputs": [],
      "source": [
        "###"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}